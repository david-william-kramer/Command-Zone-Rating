---
title: "Automated Pitching Command Metric: Command Zone Rating (CZR)"
author: "David Kramer"
date: "Spring 2022"
output: github_document
---

# Load Necessary Packages
```{r load packages}
#Import necessary packages
library(tidyverse)
library(janitor)
library(lubridate)
library(ggridges)
library(gridExtra)
library(fastDummies)
library(imputeTS)
library(xgboost)
library(randomForest)
```

## Preparing the Pre-Game Metric Data
The Command Zone Rating metric takes four sets of data sets as its input. We will input the first set of data, the pre-game metric data for both hitters and pitchers, in the section below.
```{r import pregame data}
#Import the pregame hitting and pregame pitching data sets
pregamepitching <- read.csv("C:/Users/david/Desktop/Pitcher Pre-Game Metrics.csv", header = TRUE)

pregamehitting <- read.csv("C:/Users/david/Desktop/Hitter Pre-Game Metrics.csv", header = TRUE)
```

Given the tendency for additional NA columns and rows to pollute the uploaded CSV files, we will reduce the data sets to the columns of interest and eliminate rows containing NA values. Will we also ensure that the name of the "Date" column is appropriately named. 
```{r initial cleaning of pregame}
#Conduct initial cleaning to remove all NA rows and columns
pregamepitching <- pregamepitching[, 1:20]
pregamepitching <- na.omit(pregamepitching)

pregamehitting <- pregamehitting[, 1:18]
pregamehitting <- na.omit(pregamehitting)

colnames(pregamepitching)[1] = c("Date")
colnames(pregamehitting)[1] = c("Date")
```

In anticipation of final data set merging, we will distinguish pre-game pitching metric names from pre-game hitting metric names with appropriate suffixes:
```{r pregame variable names}
for(i in 4: ncol(pregamepitching)){
  colnames(pregamepitching)[i] <- paste("pre_", 
                                        paste(colnames(pregamepitching)[i], "_pitch", sep =""), 
                                        sep = "")
}

for(i in 4: ncol(pregamehitting)){
  colnames(pregamehitting)[i] <- paste("pre_", 
                                       paste(colnames(pregamehitting)[i], "_hit", sep =""),
                                       sep = "")
}

pregamepitching <- separate(pregamepitching, 
                            "pre_w.l_pitch", 
                            into = c("pre_w_pitch", "pre_l_pitch"))
head(pregamepitching)
```

Next, we will convert the columns of the pre-game data sets to their appropriate types.
```{r variable type conversion}
pregamepitching <- pregamepitching %>%
  clean_names() %>%
  mutate(pre_w_pitch = as.integer(pre_w_pitch),
         pre_l_pitch = as.integer(pre_l_pitch))

pregamehitting <- pregamehitting %>%
  clean_names() %>%
  rename("batter" = "name")
  

head(pregamepitching, 15)
head(pregamehitting, 15)
```

This procedure makes everything in the Pre-Game Metrics data sets clean and ready for model deployment.

# Preparing the TrackMan and Pitch Zone Data: An Automated Iterative Approach 
Now, we turn to merging the pre-game data with TrackMan data sets and pitch tagging data sets.

We will boost the efficiency of this merging process through iterative automation. So long as the user of the Command Zone Rating metrics employs the same naming conventions for each file, they will simply need to update the list of game dates below with the additional date, and all files will be loaded and merged accordingly. 

### Please follow the given naming conventions:
For TrackMan files: Title = "Month_Day_Year_TrackMan.csv"

For Zone Tagging files: Title = "Month_Day_Year_Pitching_Zones.csv"

These conventions maintain the full automation of the Command Zone Rating calculation.
```{r running game date list}
#Create a list of game dates, separated by underscores
game_dates <- c("3_25_2022", "3_29_2022", "4_05_2022", "4_08_2022", 
                "4_09_2022", "4_10_2022", "4_12_2022", "4_19_2022", 
                "4_20_2022", "4_22_2022", "4_23_2022", "4_24_2022")
game_dates
```

#### The interative join function
The following iterative loop takes each appropriately named TrackMan and Pitching Zones files as inputs and merges them in the following way:

First, the TrackMan and Pitching Zone files from a given game date are joined.

Second, the pre-game pitching and hitting metrics from that game are left joined.

Then, the merged data frame object is stored as an element in the list

Finally, the rows of all data frame objects  (one for each game date) are combined using the rbind() function. 
```{r data merging iterations}
#Create empty lists for use in data merging. Each list contains one element for each game date in the final metric data set
zones <- vector("list", length(game_dates))
trackman <- vector("list", length(game_dates))
joined_zones_trackman <- vector("list", length(game_dates))
joined_add_pre_pitching <- vector("list", length(game_dates))
joined_add_pre_hitting <- vector("list", length(game_dates))

#Set the root of the working data, to be adjusted as needed
directory <- "C:/Users/david/Desktop/"

#Iterate through each TrackMan and Pitching Zones file, adding them as dataframes to their respective lists for each game. This process involves removing NA columns and rows, cleaning the data feature names, and establishing appropriate column names for "index" features. 
for(i in 1:length(game_dates)){
    trackman_name <- paste(game_dates[i], "_TrackMan.csv", sep = "")
    zones_name <- paste(game_dates[i], "_Pitching_Zones.csv", sep = "")
    print(trackman_name)
    print(zones_name)
    zones[[i]] <- read_csv(paste(directory, zones_name, sep = ""))
    zones[[i]] <- zones[[i]][, 1:6] %>%
      na_if("na") %>%
      na.omit() %>%
      na_if("Null") %>%
      na.omit() %>%
      clean_names() %>%
      mutate(pitch_number = as.integer(pitch_number),
             prepitch = as.character(prepitch),
             postpitch = as.character(postpitch))
    print(colnames(zones[[i]]))
    trackman[[i]] <- read.csv(paste(directory, trackman_name, sep = ""))
    trackman[[i]] <- trackman[[i]] %>%
      clean_names() %>%
      mutate(date = mdy(date),
             game_foreign_id = as.character(game_foreign_id)) %>%
      separate(batter, into = c("last", "first"), sep = ", ") %>%
      unite("batter", c("first", "last"), sep = " ", remove = TRUE) %>%
      rename(pitch_number = pitch_no)
    joined_zones_trackman[[i]] <- inner_join(zones[[i]], 
                                             trackman[[i]], 
                                             by = "pitch_number") %>%
      select(-date.y) %>%
      rename("date" = "date.x")
    joined_add_pre_pitching[[i]] <- left_join(joined_zones_trackman[[i]], 
                                               pregamepitching,
                                               by = c("date", "player"))
    joined_add_pre_hitting[[i]] <- left_join(joined_add_pre_pitching[[i]],
                                             pregamehitting,
                                             by = c("date", "batter"))
}
#Join the rows of each merged data frame object in the condensed list of TrackMan / Pitching Zones / Pre-Game Metrics data frames

full_metric_data <- joined_add_pre_hitting %>%
  bind_rows() %>%
  mutate(prepitch = as.integer(prepitch),
         postpitch = as.integer(postpitch),
         date = mdy(date)) %>%
  drop_na(prepitch)

#Inspect the full metric data frame 
head(full_metric_data, 20)
dim(full_metric_data)
```

## Zone Difference: Calculation
Before the iterative model-building calculation begins, we need to calculate the absolute zone difference of each pitch thrown in the full metric data set.

The Zone Difference variable will sum the absolute value of horizontal zone differential and the absolute value of horizontal zone differential for a total Zone Differential score. 

In preparation for this summation, we will create a data frame that represents the 25-zone grid for the sake of Zone Differential Calculation.
```{r create zone grid}
zone_grid <- matrix(0, ncol = 5, nrow = 5)
zone_grid
```

We will fill this 5 x 5 matrix with the corresponding zone numbers:
```{r fill zone grid}
for(i in 1:nrow(zone_grid)){
  for(j in 1:ncol(zone_grid)){
    zone_grid[i,j] = 5*(i-1) + j
  }
}
zone_grid
```

This grid will allow us to calculate the absolute zone differential (the sum of absolute horizontal zone difference and absolute vertical zone difference), as shown in an iterative approach below:
```{r zone differential calculation}
zone_difference <- rep(NA, nrow(full_metric_data))
for(i in 1:nrow(full_metric_data)){
  pre_pitch_zone <- full_metric_data$prepitch[i]
  post_pitch_zone <- full_metric_data$postpitch[i]
  pre_pitch_zone_row <- which(zone_grid == pre_pitch_zone, arr.ind = TRUE)[1]
  pre_pitch_zone_column <- which(zone_grid == pre_pitch_zone, arr.ind=TRUE)[2]
  post_pitch_zone_row <- which(zone_grid == post_pitch_zone, arr.ind = TRUE)[1]
  post_pitch_zone_column <- which(zone_grid == post_pitch_zone, arr.ind=TRUE)[2]
  
  zone_difference[i] <- abs(pre_pitch_zone_row - post_pitch_zone_row) + abs(pre_pitch_zone_column - post_pitch_zone_column)
}
```

With all zone differential values calculated in a list, we will append the list to the full metric data set for future analysis and incorporation into the Command Zone Rating calculation.
```{r view zone_difference}
full_metric_data <- full_metric_data %>%
  mutate(zone_diff = zone_difference)

head(full_metric_data[, 205:207], 20)
```
## Zone Difference: Visualization and Data Exploration
Let's explore whether or not any relationships exist in the data set between zone differential and the handedness of the batter and pitcher.
```{r zone difference visualizations}
#Plot 1: Zone difference by pitch type, as tagged by the TrackMan operator at ND Baseball
plot1 <- ggplot(full_metric_data, aes(x = zone_diff, 
                                      y = reorder(tagged_pitch_type, 
                                                  zone_diff), 
                                      fill = tagged_pitch_type)) + 
  geom_density_ridges(alpha = 0.5) + # Use geom density ridges for 3d density
   theme(axis.line = element_line(colour = "black"), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        panel.border = element_blank(), 
        panel.background = element_blank()) +  
  labs(x = "Zone Difference", 
       y = "Pitch Type",  # Set labels
       title = "Zone Difference by Pitch Type",
       subtitle = "Distribution Shapes") +
  guides(fill = FALSE)

#Plot 2: Zone difference by Right-Handed vs. Left-Handed batters
plot2 <- ggplot(full_metric_data, aes(x = zone_diff, 
                                      y = reorder(batter_side, 
                                                  zone_diff), 
                                      fill = batter_side)) + 
  geom_density_ridges(alpha = 0.5) + 
   theme(axis.line = element_line(colour = "black"), 
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(), 
        panel.border = element_blank(), 
        panel.background = element_blank()) + 
  labs(x = "Zone Difference", 
       y = "Batter Handedness", 
       title = "Zone Difference by Batter Handedness",
       subtitle = "Distribution Shapes") +
  guides(fill = FALSE)

#Plot 3: Zone difference by Right-Handed vs. Left-Handed Pitchers
plot3 <- ggplot(full_metric_data, aes(x = zone_diff, y = reorder(pitcher_throws, zone_diff), fill = pitcher_throws)) + 
  geom_density_ridges(alpha = 0.5) + 
   theme(axis.line = element_line(colour = "black"), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        panel.border = element_blank(), 
        panel.background = element_blank()) + 
  labs(x = "Zone Difference", 
       y = "Pitcher Handedness",  
       title = "Zone Difference by Pitcher Handedness",
       subtitle = "Distribution Shapes") +
  guides(fill = FALSE)

#View the plot distributions
plot1
grid.arrange(plot2, plot3, ncol=2)
```

For a more granular look at the analysis presented above, let's combine pitcher and batter handedness to consider if L / L and R / R match-ups present command problems: 
```{r more zone differnce visualizations }
full_metric_data <- full_metric_data %>%
  unite("batter_pitcher", c("batter_side", "pitcher_throws"), remove = FALSE)

plot4 <- ggplot(full_metric_data, aes(x = zone_diff, y = reorder(batter_pitcher, zone_diff), fill = batter_pitcher)) + # Set aesthetics
  geom_density_ridges(alpha = 0.5) + # Use geom density ridges for 3d density
   theme(axis.line = element_line(colour = "black"), # Set axis line as black
        panel.grid.major = element_blank(), # Remove grid
        panel.grid.minor = element_blank(), # Remove grid
        panel.border = element_blank(), # Remove grid
        panel.background = element_blank()) + # Remove grid 
  labs(x = "Zone Difference", 
       y = "Pitcher Handedness",  # Set labels
       title = "Zone Difference by Pitcher Handedness",
       subtitle = "Distribution Shapes") +
  guides(fill = FALSE)

plot4
```

Finally, we will aggregate the zone differentials into an overall histogram, filtered by pitch type, for a high-level look at the variable distribution:
```{r zone difference historgram}
ggplot(data = full_metric_data, mapping = aes(x = zone_diff, fill = tagged_pitch_type)) +
  geom_bar() +
  labs(x = "Zone Differential", 
       y = "Frequency", 
       fill = "Pitch Type",
       title = "Zone Differential by Pitch Type", 
       subtitle = "Overall Frequency") + 
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        axis.line = element_line(colour = "black"))
```

Given its automation, the above visualizations will vary as new data sets are introduced into the Command Zone Rating metric calculation. The plot images may be extracted for advanced pitching analysis as requested. 

## Variable Selection for the Model-Building Process
This merged data set contains a large proportion of features that are not needed for the Command Zone Rating calculation. The following variable reduction modifications become necessary:

1. Given the collection of pre-game hitting data throughout the season, we will limit the included pre-game metrics to standardized composite metrics that are independent of the number of games played. As such, we ensure that the included metrics (batting average, on-base percentage, slugging percentage, etc.) do not place inaccurate weight on these features in the model based on their wide variance.

2. Given the collection of pre-game pitching data throughout the season, we will limit the included pre-game metrics to standardized composite metrics that are independent of the number of games played. As such, we ensure that the included metrics (ERA, WHIP, K/9 IP, wins + saves per appearance, etc.) do not place inaccurate weight on these features in the model based on their wide variance.

3. Many of the variables from the raw TrackMan file that document the ball flight are independent of the question of pitching command. While the individual pitching metrics like velocity, vertical approach angle, and spin rate are relevant for Command Zone Rating model-building, some of the ball-in-play metrics, such as exit velocity and launch angle, are not reflective of individual pitcher command. In preparation for model predictions, which take the average TrackMan pitching metrics and NCAA league average hitting metrics as inputs for raw probability scores, we will limit the use of TrackMan to these pitcher-specific measurements.

4. Duplicate ID columns and redundant measurements may be removed.

5. Ultimately, we will segment the data based on "Ball Zones" (16 zones beyond the 9 strike zones) and "Base Hit Zones" (9 zones within the strike zones) and convert the Play Result to binary categorical variables of Ball Called / No Balled Called and Base Hit / No Base Hit, respectively. 

Let's make a list of the variables that we will need in this merged data set in anticipation of removal. To do that, we will first need the full list of column names:
```{r view column names of full data}
colnames(full_metric_data)
```

Next, remove the metrics pertaining to ball flight and other irrelevant measures with respect to command:
```{r}
metric_vars_list <- c("date",
                      "team",
                      "player",
                      "prepitch",
                      "postpitch",
                      "batter_side",
                      "outs",
                      "balls",
                      "strikes",
                      "inning",
                      "tagged_pitch_type",
                      "pitch_call",
                      "play_result",
                      "kor_bb",
                      "rel_speed",
                      "vert_rel_angle",
                      "horz_rel_angle",
                      "spin_rate",
                      "spin_axis",
                      "tilt",
                      "rel_height",
                      "rel_side",
                      "extension",
                      "vert_break",
                      "induced_vert_break",
                      "horz_break",
                      "zone_speed",
                      "vert_appr_angle",
                      "horz_appr_angle",
                      "pre_era_pitch",
                      "pre_w_pitch",
                      "pre_l_pitch",
                      "pre_sv_pitch",
                      "pre_app_pitch",
                      "pre_ip_pitch",
                      "pre_h_pitch",
                      "pre_bb_pitch",
                      "pre_so_pitch",
                      "pre_x2b_pitch",
                      "pre_x3b_pitch",
                      "pre_hr_pitch",
                      "pre_b_avg_pitch",
                      "pre_ab_hit",
                      "pre_h_hit",
                      "pre_x2b_hit",
                      "pre_x3b_hit",
                      "pre_hr_hit",
                      "pre_rbi_hit",
                      "pre_tb_hit",
                      "pre_bb_hit",
                      "pre_so_hit",
                      "pre_obp_hit",
                      "pre_slg_hit",
                      "zone_diff")

metrics_reduced_model_data <- subset(full_metric_data, select = metric_vars_list)

head(metrics_reduced_model_data)
```


## Variable Creation: Standardized Hitting and Pitching Metrics

In this section, we will create a list of pitching and hitting metrics that can be compared over time as pre-game metric data sets from various points in the NCAA season are introduced. 

The following standardized metrics will be calculated, among others:

1. Batting Average

2. Walks + Hits / Innings Pitched (WHIP)

3. Strikeouts per Inning Pitched (K/IP)

4. Wins + Saves / Appearances (WS / APP)

5. Fielding Independent Pitching (FIP)

6. Total Bases / Innings Pitched (Proxy for Opponent OPS)

Pitching Metrics: Fielding Independent Pitching, OPPOPS, Strikeouts per IP, WHIP, WS / APP: 
```{r}
metrics_reduced_model_data <- metrics_reduced_model_data %>%
  mutate(pre_w_pitch = as.double(pre_w_pitch),
         pre_sv_pitch = as.double(pre_sv_pitch),
         pre_app_pitch = as.integer(pre_app_pitch)) %>%
  mutate(pre_w_pitch = if_else(is.na(pre_w_pitch), 0, pre_w_pitch)) %>%
  mutate(fip = (13 * pre_hr_pitch  + 3 * pre_bb_pitch - 2 * pre_so_pitch) / pre_ip_pitch,
         opp_ops = (2*pre_x2b_pitch + 
                      3*pre_x3b_pitch + 
                      4*pre_hr_pitch + 
                      (pre_h_pitch - pre_x2b_pitch - pre_x3b_pitch - pre_hr_pitch)*1)/ pre_ip_pitch,
         wins_saves_app = (pre_w_pitch + pre_sv_pitch) / pre_app_pitch,
         k_per_ip = pre_so_pitch / pre_ip_pitch,
         whip = (pre_bb_pitch + pre_h_pitch)/ pre_bb_pitch)

head(metrics_reduced_model_data) 
```

Hitting Metrics: OPS, BB / AB, SO / AB
```{r}
metrics_reduced_model_data <- metrics_reduced_model_data %>%
  mutate(ops = pre_obp_hit + pre_slg_hit,
         bb_per_ab = pre_bb_hit / pre_ab_hit,
         pre_so_hit = as.numeric(pre_so_hit),
         so_per_ab = pre_so_hit / pre_ab_hit)

head(metrics_reduced_model_data)
```

Now, reduce the variables in the metric model data set to the standardized metrics used for filtering and modeling for CZR:
```{r}
metrics_reduced_model_data <- metrics_reduced_model_data %>%
  select(date,
         player,
         team,
         pitch_call,
         play_result,
         zone_diff,
         postpitch, 
         batter_side, 
         outs, 
         balls, 
         strikes, 
         inning, 
         tagged_pitch_type,
         pitch_call,
         play_result,
         rel_speed,
         vert_rel_angle,
         horz_rel_angle,
         spin_rate,
         spin_axis,
         extension,
         vert_break,
         induced_vert_break,
         horz_break,
         zone_speed,
         vert_appr_angle,
         horz_appr_angle,
         pre_era_pitch,
         pre_b_avg_pitch,
         fip,
         opp_ops,
         wins_saves_app,
         k_per_ip,
         ops,
         bb_per_ab,
         so_per_ab,
         whip) %>%
  mutate(batter_side = as.factor(batter_side),
         outs = as.factor(outs),
         balls = as.factor(balls),
         strikes = as.factor(strikes),
         inning = as.factor(inning),
         tagged_pitch_type = as.factor(tagged_pitch_type))

head(metrics_reduced_model_data)
```

# Create the Results Data Frame

In anticipation of model building, we must build a data frame that contains the following:

1. 25 factor variables across 25 columns, one corresponding to each zone, with ones in the diagonal for a total of 25 rows

2. The average pitching metrics for a given pitcher's pitch type by hitter handedness (R/L)

3. The aggregate mean NCAA hitting metrics among faced teams in the data set

4. An empty column in which corresponding test predictions on these observational rows will be placed

5. The pitch splits of each pitcher for the sake of filtering out pitches thrown less than 20 percent of the time

I will begin by calculating the pitch splits by player among all pitches thrown in the data set:
```{r}
metrics_reduced_model_data <- metrics_reduced_model_data %>%
  mutate(team = if_else(team == "ND", "Notre Dame", team)) 

by_pitch <- metrics_reduced_model_data %>%
  filter(team == "Notre Dame") %>%
  group_by(player, tagged_pitch_type) %>%
  count()

by_pitch

by_total_pitches <- metrics_reduced_model_data %>%
  filter(team == "Notre Dame") %>%
  group_by(player) %>%
  count()

by_total_pitches

by_pitcher_joined <- by_pitch %>%
  left_join(by_total_pitches,
            by = "player") %>%
  mutate(pitch_split = n.x / n.y) %>%
  select(-c(n.x, n.y)) %>%
  filter(pitch_split >= 0.2)

by_pitcher_joined
```

Next, I will create dummy variables for post pitch zones and convert them into factors
```{r}
metric_results <- metrics_reduced_model_data %>%
  select(postpitch) %>%
  dummy_cols() %>%
  unique() %>%
  arrange(postpitch) %>%
  drop_na() %>%
  select(-c(postpitch, postpitch_NA)) %>%
  mutate(across(.cols = everything(), as.factor))

head(metric_results)
```

The following combinations grid creates a set of 25 eligible test rows per model (dependent on a given player, batter side, pitch type combination and tested on the corresponding rows):
```{r}
combinations_grid <- by_pitcher_joined %>%
   dplyr::slice(rep(1:n(), each = 2))

batter_side <- rep(c("Left", "Right"), nrow(combinations_grid)/2)

combinations_grid$batter_side <- as.factor(batter_side)

head(combinations_grid, 20)
```

The following aggregations calculate the following:

1. The pregame metrics of a pitcher from his last appearance in a game in the data set

2. The average hitting metrics across NCAA hitters faced by Notre Dame

3. The average TrackMan pitching metrics by player, pitch type, and batter handedness

The resulting data sets are joined on the data frame of bounded eligible test rows (thus forming the basis for predictions on each model as features):
```{r}
head(metrics_reduced_model_data)

case_when_for_first_appearance <- function(x) {
  case_when(is.na(x) ~ mean(x, na.rm=TRUE),
            TRUE ~ as.numeric(x))
}

average_trackman_metrics_by_pitcher <- metrics_reduced_model_data %>%
  filter(team == "Notre Dame") %>%
  select(c(player, tagged_pitch_type, batter_side, 14:25)) %>%
  group_by(player, tagged_pitch_type, batter_side) %>%
  summarise_if(is.numeric, mean, na.rm = TRUE) %>%
  distinct()

last_pitching_appearance_pregame <- metrics_reduced_model_data %>%
  filter(team == "Notre Dame") %>%
  group_by(player) %>%
  summarise(max(date)) %>%
  rename("date" = "max(date)") %>%
  left_join(metrics_reduced_model_data,
            by = c("player", "date")) %>%
  select(c(1, 8, 13, 26:31, 35)) %>%
  mutate(across(4:10, case_when_for_first_appearance)) %>%
  distinct()
  
average_ncaa_hitting_metrics <- metrics_reduced_model_data %>%
  mutate(across(32:34, mean, na.rm = TRUE)) %>%
  select(32:34) %>%
  distinct()


metric_results_matrix_list <- vector("list", nrow(combinations_grid))
for(i in 1:length(metric_results_matrix_list)){
  metric_results_matrix_list[[i]] <- metric_results
  metric_results_matrix_list[[i]]$player <- rep(combinations_grid$player[i], 25)
  metric_results_matrix_list[[i]]$batter_side <- rep(combinations_grid$batter_side[i], 25)
  metric_results_matrix_list[[i]]$tagged_pitch_type <- rep(combinations_grid$tagged_pitch_type[i], 25)
  metric_results_matrix_list[[i]]$pitch_split <- rep(combinations_grid$pitch_split[i], 25)
  metric_results_matrix_list[[i]]$ops <- rep(average_ncaa_hitting_metrics$ops, 25)
  metric_results_matrix_list[[i]]$bb_per_ab <- rep(average_ncaa_hitting_metrics$bb_per_ab, 25)
  metric_results_matrix_list[[i]]$so_per_ab <- rep(average_ncaa_hitting_metrics$so_per_ab, 25)
  metric_results_matrix_list[[i]] <- metric_results_matrix_list[[i]] %>%
    left_join(average_trackman_metrics_by_pitcher,
              by = c("player",
                     "batter_side",
                     "tagged_pitch_type")) %>%
    left_join(last_pitching_appearance_pregame,
              by = c("player",
                     "batter_side",
                     "tagged_pitch_type"))
  metric_results_matrix_list[[i]]$model_number <- paste("model_", i)
}

bounded_results_matrix <- metric_results_matrix_list %>%
  bind_rows() %>%
  mutate(across(1:25, as.character)) %>%
  mutate(across(1:25, as.integer))


head(bounded_results_matrix, 200)

dim(bounded_results_matrix)
```

Here, we would expand the predictions by individual game situations and their respective WPA / EPA implications (pitch count, inning, pitch number in the outing, number of base runners, runner positions, pitch number in the at bat). However, for the sake of simplicity in this model, we will move forward will reducing the variable list in the test observations to those necessary for model predictions. We will also ensure that both the training set and "test" predictions set possess the same variable names and types:
```{r}
final_metric_vars_list <- c(colnames(bounded_results_matrix), "postpitch", "zone_diff", "pitch_call", "play_result")
final_metric_vars_list <- final_metric_vars_list[final_metric_vars_list != c("pitch_split", "model_number")]
final_metric_vars_list

final_metric_model_data <- metrics_reduced_model_data %>%
  mutate(postpitch = as.factor(postpitch)) %>%
  dummy_cols(select_columns = "postpitch") %>%
  select(final_metric_vars_list)

head(final_metric_model_data)
```

Next, I will create lists of ball zones and strike zones for use in the two models' applications:
```{r}
ball_zone_list <- c(1:6, 10:11, 15:16, 20:25)
strike_zone_list <- c(7:9, 12:14, 17:19)
```

I will store the total zones per player in a data frame in anticipation of the final metric calculation:
```{r}
total_zones_by_pitcher <- metrics_reduced_model_data %>%
  filter(team == "Notre Dame") %>%
  group_by(player) %>%
  summarise(total_zone_diff = sum(zone_diff, na.rm = TRUE))
```

I will divide final metric model data into pitches missed in ball zones and pitches missed in strike zones:
```{r}
final_metric_ball_data <- final_metric_model_data %>%
  mutate(ball_called = if_else(pitch_call == "BallCalled", 1, 0)) %>%
  select(-c("pitch_call", "play_result")) %>%
  filter(zone_diff > 0 & postpitch %in% ball_zone_list) %>%
  select(-c("zone_diff", "postpitch")) %>%
  mutate(ball_called = as.factor(ball_called))


head(final_metric_ball_data)

unique(final_metric_model_data$pitch_call)

final_metric_strike_data <- final_metric_model_data %>%
  mutate(strike_hit = if_else(pitch_call %in% c("FoulBall", "InPlay"), 1, 0)) %>%
  select(-c("pitch_call", "play_result")) %>%
  filter(zone_diff > 0 & postpitch %in% strike_zone_list) %>%
  select(-c("zone_diff", "postpitch")) %>%
  mutate(strike_hit = as.factor(strike_hit))

head(final_metric_strike_data, 10)

bounded_results_matrix$preds <- as.numeric(rep(NA, nrow(bounded_results_matrix)))

head(bounded_results_matrix, 10)
```

As mentioned, the variables in the testing grid above must match the variable types and names of the variables in the training set for XGBoost. Please confirm before continuing. 

# Model Building

## First Potential Model: XGBoost

If XGBoost is your preferred modeling technique within CZR, please conduct the following small-scale test, evaluate the results, and replace random forest with XGBoost in the iterative loop for CZR below 

To begin, I will build two models to test the structure of the iterative loop:

### Models 1 and 2 Conditions: Player = John Michael Bertrand, Pitch Type = Fastball, Batter = Right

Model 1: John Michael Bertrand, Fastball, RHH, Strike Zones 
```{r}
bertrand_model1_data <- final_metric_strike_data %>%
  filter(player == "John Michael Bertrand",
         batter_side == "Right",
         tagged_pitch_type == "Fastball") %>%
  select(-c(26:28)) %>%
  na_mean()

rownames(bertrand_model1_data) <- NULL

bertrand_model1_data

scale_weight = sum(bertrand_model1_data$strike_hit == 0) / sum(bertrand_model1_data$strike_hit == 1)
```

Build the training set, build the model, and evaluate the predictions on the testing set (where eligible):
```{r}
dtrain <- xgb.DMatrix(data = as.matrix(bertrand_model1_data[,-48]), 
                      label = as.numeric(bertrand_model1_data$strike_hit) -1)

set.seed(574)
bst_bertrand_1 <- xgboost(data = dtrain, 
               nrounds = 100,
               verbose = 1, 
               nthread = 1,
               print_every_n = 20, 
               objective = "binary:logistic", 
               eval_metric = "auc",
               eval_metric = "error",
               scale_pos_weight = scale_weight)


```

Extract the variable importance to verify if XGBoost accounts for pitching zones as important factors in the model (if not, random forest may be a better fit in light of the data availability):
```{r}
# Extract importance
imp_mat <- xgb.importance(model = bst_bertrand_1)
# Plot importance (top 10 variables)
xgb.plot.importance(imp_mat, 
                    top_n = 10, 
                    main = "John Michael Bertrand, Model 1: Variable Importance")
```

Filter for the pertinent, eligible testing rows for Model 1's conditions:
```{r}
test_row <- bounded_results_matrix %>%
  filter(player == "John Michael Bertrand",
         batter_side == "Right",
         tagged_pitch_type == "Fastball") %>%
  select(-c("preds", "player", "batter_side", "tagged_pitch_type", "model_number", "pitch_split"))  %>%
  filter(row_number() %in% strike_zone_list)

test_row$strike_hit <- as.factor(0)

test_row
```

Apply the predictions (9 here):
```{r}
dtest <- xgb.DMatrix(data = as.matrix(test_row[,-48]), 
                      label = as.numeric(test_row$strike_hit) -1)
xgb_preds_1 <- predict(bst_bertrand_1, dtest)

xgb_preds_1
```

Model 2: Bertrand, Fastball, RHH, Ball Zones

I will perform the same procedure on all pitches thrown in the ball zones that match the Model 2 conditions:
```{r}
bertrand_model2_data <- final_metric_ball_data %>%
  filter(player == "John Michael Bertrand",
         batter_side == "Right",
         tagged_pitch_type == "Fastball") %>%
  select(-c(26:28)) %>%
  na_mean()

rownames(bertrand_model2_data) <- NULL

bertrand_model2_data

scale_weight = sum(bertrand_model2_data$ball_called == 0) / sum(bertrand_model2_data$ball_called == 1)
```

Form the training set and build the ball called model: 
```{r}
dtrain <- xgb.DMatrix(data = as.matrix(bertrand_model2_data[,-48]), 
                      label = as.numeric(bertrand_model2_data$ball_called) -1)

set.seed(574)
bst_bertrand_2 <- xgboost(data = dtrain, 
               nrounds = 100,
               verbose = 1, 
               nthread = 1,
               print_every_n = 20, 
               objective = "binary:logistic", 
               eval_metric = "auc",
               eval_metric = "error",
               scale_pos_weight = scale_weight)
```

As above, verify that certain zones possess an impact on the model (if not, opt for random forest modeling to ensure zone impact):
```{r}
# Extract importance
imp_mat_2 <- xgb.importance(model = bst_bertrand_2)
# Plot importance (top 10 variables)
xgb.plot.importance(imp_mat_2, 
                    top_n = 10, 
                    main = "John Michael Bertrand, Model 2: Variable Importance")
```

Detect the pertinent, eligible testing rows, and apply the testing rows on the model for the sake of prediction scores:
```{r}
test_row_2 <- bounded_results_matrix %>%
  filter(player == "John Michael Bertrand",
         batter_side == "Right",
         tagged_pitch_type == "Fastball") %>%
  filter(row_number() %in% ball_zone_list) %>%
  select(-c("preds", "player", "batter_side", "tagged_pitch_type", "model_number", "pitch_split")) 

test_row_2$ball_called <- as.factor(0)

test_row_2
```

Calculate the prediction scores (16 out of 16 eligible in this case due to factorless approach in XGBoost):
```{r}
dtest <- xgb.DMatrix(data = as.matrix(test_row_2[,-48]), 
                      label = as.numeric(test_row_2$ball_called) -1)
xgb_preds_1 <- predict(bst_bertrand_2, dtest)

xgb_preds_1
```

## Second Model Option: Random Forest

To ensure that zone locations generate an impact in the model's structure, random forest modeling may be beneficial for CZR calculations. Here, we investigate the same model conditions (Bertrand, fastball, RHH, Strike Zones and Ball Zones) for Models 1 and 2, respectively, noticing the prediction score adjustments when accounting for zone locations.

We form the data sets, build the first model, and test which of the eligible rows in the testing set correspond to any observations in the training set. If no rows in the training set correspond to a pitch in a testing row's respective zone, remove that row from the data frame of testing rows for the Model 1 conditions and continue:
```{r}
bertrand_model1_data <- bertrand_model1_data %>%
  mutate(across(1:25, as.factor))

bertrand_model2_data <- bertrand_model2_data %>%
  mutate(across(1:25, as.factor))

set.seed(574)
bertrand_rf_mod_1 <- randomForest(strike_hit ~., 
                         data = bertrand_model1_data, 
                         ntree = 100,
                         nodesize = 1,
                         mtry = 47) 

test_row <- bounded_results_matrix %>%
  filter(player == "John Michael Bertrand",
         batter_side == "Right",
         tagged_pitch_type == "Fastball") %>%
  select(-c("preds", "player", "batter_side", "tagged_pitch_type", "model_number", "pitch_split"))

bertrand_model1_data <- bertrand_model1_data %>%
  mutate(across(1:25, as.character)) %>%
  mutate(across(1:25, as.integer))

test_row$strike_hit <- as.factor(0)

row_list <- vector()

for(i in 1:25){
  if(sum(bertrand_model1_data[, i]) == 0){
    row_list <- append(row_list, i)
    }
}

test_row <- test_row[-row_list, ]

test_row <- test_row %>%
  mutate(across(1:25, as.factor))
```

Applying the model on the remaining testing rows and evaluating the prediction scores (9 out of 9 in this case):
```{r}
rf_bertrand_preds <- predict(bertrand_rf_mod_1, test_row, type = "prob") 

rf_bertrand_preds

nrow(rf_bertrand_preds)
```

We build the second model and test which of the eligible rows in the testing set correspond to any observations in the training set. If no rows in the training set correspond to a pitch in a testing row's respective zone, remove that row from the data frame of testing rows for the Model 2 conditions and continue:
```{r}
set.seed(574)
bertrand_rf_mod_2 <- randomForest(ball_called ~., 
                         data = bertrand_model2_data, 
                         ntree = 100,
                         nodesize = 1,
                         mtry = 47) 

bertrand_model2_data <- bertrand_model2_data %>%
  mutate(across(1:25, as.character)) %>%
  mutate(across(1:25, as.integer))

test_row_2 <- bounded_results_matrix %>%
  filter(player == "John Michael Bertrand",
         batter_side == "Right",
         tagged_pitch_type == "Fastball") %>%
  select(-c("preds", "player", "batter_side", "tagged_pitch_type", "model_number", "pitch_split")) 

test_row_2$ball_called <- as.factor(0)

test_row_2

row_list <- vector()

for(i in 1:25){
  if(sum(bertrand_model2_data[, i]) == 0){
    row_list <- append(row_list, i)
    }
}

test_row_2 <- test_row_2[-row_list, ]

test_row_2 <- test_row_2 %>%
  mutate(across(1:25, as.factor))
```

Applying the model on the remaining testing rows for predictions, and evaluating the prediction scores:
```{r}
rf_bertrand_preds_2 <- predict(bertrand_rf_mod_2, test_row_2, type = "prob") 

rf_bertrand_preds_2[, 2]

nrow(rf_bertrand_preds_2)

zones_list <- seq(1, 25, 1)
cbind()
```

# Part 1: Given Thrown In Strike Zone, Base Hit Probabilities

Now that one case of successful predictions has been conducted, the above calculation can be repeated in a nested for loop for all other Pitcher, Pitch Type, and Batter Side combinations in the data set for Notre Dame pitchers. The following for loop conducts the following for Strike Zone pitches:

1. Iterate through Pitchers, Batter Sides, and Pitch Types, building a model on the corresponding observations for each combination

2. Replace infinite WHIP values with a manageable replacement proxy (near 100)

3. Test if the model contains enough data to build a tree ensemble. If only one class exists in the response value, the model's conditions fail, and a given model is skipped. All predictions are negated. 

4. Test if a testing row's corresponding zone is in the training set. If no association exists, remove the row from a given model's corresponding testing rows and continue. 

5. Append the model predictions to the matrix of bounded testing results, one for each zone. These prediction scores, along with the total misses per zone and total pitches thrown in a zone as grouped by the model conditions, will be used to calculate the Command Score (the impact component of CZR).

All models will be either skipped or built for immediate application on corresponding available test rows (in this case, limited to the 9 eligible strike zones):
```{r}
bounded_individual_pitchers_strike <- vector("list", dim(bounded_results_matrix)[1] / 25)

identifiers <- bounded_results_matrix %>%
  select(26:28) %>%
  distinct() %>%
  mutate(batter_side = as.character(batter_side),
         tagged_pitch_type = as.character(tagged_pitch_type))

player_list <- as.list.data.frame(identifiers$player)

batter_list <- as.list.data.frame(identifiers$batter_side)

pitch_list <- as.list.data.frame(identifiers$tagged_pitch_type)

for(i in 1:length(player_list)){
      strike_model_data <- final_metric_strike_data %>%
        filter(player == player_list[i],
               as.character(batter_side) == batter_list[i],
               as.character(tagged_pitch_type) == pitch_list[i]) %>%
        select(-c(26:28)) %>%
        na_mean() %>%
        mutate(whip = replace(whip, whip == Inf, 99))
      
      strike_model_data_int <- strike_model_data %>%
        mutate(strike_hit = as.character(strike_hit),
               strike_hit = as.integer(strike_hit))
      
      if(sum(strike_model_data_int$strike_hit) == 0 | sum(strike_model_data_int$strike_hit) == nrow(strike_model_data_int)){
        cat("Not Enough Data for ", player_list[i], ", ", batter_list[i], ", ", pitch_list[i], "Strike Model")
        cat("\n")
        next
      } else{
        print("Model Satisfies Conditions")
        cat("\n")
        rownames(strike_model_data) <- NULL
      
      strike_model_data <- strike_model_data %>%
        mutate(across(1:25, as.factor))
      
      wn = sum(strike_model_data$strike_hit == 0)/nrow(strike_model_data)
      wy = sum(strike_model_data$strike_hit == 1)/nrow(strike_model_data)
    
      set.seed(574)
      strike_rf_model <- randomForest(strike_hit ~., 
                         data = strike_model_data, 
                         ntree = 100,
                         nodesize = 1,
                         mtry = 47,
                         classwt = c(wn, wy)) 
      
      test_row <- bounded_results_matrix %>%
       filter(player == player_list[i],
               as.character(batter_side) == batter_list[i],
               as.character(tagged_pitch_type) == pitch_list[i]) %>%
        select(-c("preds", "player", "batter_side", "tagged_pitch_type", "model_number", "pitch_split"))

      strike_model_data <- strike_model_data %>%
        mutate(across(1:25, as.character)) %>%
        mutate(across(1:25, as.integer))

      test_row$strike_hit <- as.factor(0)

      row_list <- vector()

      for(x in 1:25){
        if(sum(strike_model_data[, x]) == 0){
          row_list <- append(row_list, x)
          }
      }
      
      test_row$index <- seq(1, 25)
      
      test_row <- test_row[-row_list, ]

      test_row <- test_row %>%
        mutate(across(1:25, as.factor))
      
      test_row_no_index <- test_row %>%
        select(-index)
      
      strike_model_preds <- predict(strike_rf_model, test_row_no_index, type = "prob")
      
      bounded_preds <- cbind(test_row, strike_model_preds[ ,2])
      
      colnames(bounded_preds) <- c(colnames(test_row), "model_preds")
      
      bounded_individual_pitchers_strike[[i]] <- bounded_results_matrix %>%
       filter(player == player_list[i],
               as.character(batter_side) == batter_list[i],
               as.character(tagged_pitch_type) == pitch_list[i])
      
      for(z in 1:25){
        if(z %in% row_list){
           bounded_individual_pitchers_strike[[i]][z, 53] <- NA
        } else{
           bounded_individual_pitchers_strike[[i]][z, 53] <- as.list(bounded_preds[which(bounded_preds$index == z), 50])
        }
      }
      }
}

final_bounded_results_matrix_strike <- bounded_individual_pitchers_strike %>%
  bind_rows() %>%
  filter(!is.na(preds))

colnames(final_bounded_results_matrix_strike) <- str_replace(colnames(final_bounded_results_matrix_strike), "postpitch_", "")

final_bounded_results_matrix_strike <- final_bounded_results_matrix_strike %>%
  pivot_longer(1:25, names_to = "column", values_to = "in_zone") %>%
  filter(in_zone != 0) %>%
  select(-in_zone) %>%
  rename("zone" = column) %>%
  mutate(zone = as.integer(zone)) %>%
  select(zone, player, batter_side, tagged_pitch_type, pitch_split, preds)
```

# Part 2: Given Thrown Outside Strike Zone, Ball Called Probabilities
The for loop below conducts the following for Strike Zone pitches:

1. Iterate through Pitchers, Batter Sides, and Pitch Types, building a model on the corresponding observations for each combination

2. Replace infinite WHIP values with a manageable replacement proxy (near 100)

3. Test if the model contains enough data to build a tree ensemble. If only one class exists in the response value, the model's conditions fail, and a given model is skipped. All predictions are negated. 

4. Test if a testing row's corresponding zone is in the training set. If no association exists, remove the row from a given model's corresponding testing rows and continue. 

5. Append the model predictions to the matrix of bounded testing results, one for each zone. These prediction scores, along with the total misses per zone and total pitches thrown in a zone as grouped by the model conditions, will be used to calculate the Command Score (the impact component of CZR).

All models will be either skipped or built for immediate application on corresponding available test rows (in this case, limited to the 16 eligible ball zones):
```{r}
bounded_individual_pitchers_ball <- vector("list", dim(bounded_results_matrix)[1] / 25)

identifiers <- bounded_results_matrix %>%
  select(26:28) %>%
  distinct() %>%
  mutate(batter_side = as.character(batter_side),
         tagged_pitch_type = as.character(tagged_pitch_type))

player_list <- as.list.data.frame(identifiers$player)

batter_list <- as.list.data.frame(identifiers$batter_side)

pitch_list <- as.list.data.frame(identifiers$tagged_pitch_type)

for(i in 1:length(player_list)){
      ball_model_data <- final_metric_ball_data %>%
        filter(player == player_list[i],
               as.character(batter_side) == batter_list[i],
               as.character(tagged_pitch_type) == pitch_list[i]) %>%
        select(-c(26:28)) %>%
        na_mean() %>%
        mutate(whip = replace(whip, whip == Inf, 99))
      
      ball_model_data_int <- ball_model_data %>%
        mutate(ball_called = as.character(ball_called),
               ball_called = as.integer(ball_called))
      
      if(sum(ball_model_data_int$ball_called) == 0 | sum(ball_model_data_int$ball_called) == nrow(ball_model_data_int)){
        cat("Not Enough Data for ", player_list[i], ", ", batter_list[i], ", ", pitch_list[i], "Ball Model")
        cat("\n")
        next
      } else{
        print("Model Satisfies Conditions")
        cat("\n")
        rownames(ball_model_data) <- NULL
      
      ball_model_data <- ball_model_data %>%
        mutate(across(1:25, as.factor))
      
      wn = sum(ball_model_data$ball_called == 0)/nrow(ball_model_data)
      wy = sum(ball_model_data$ball_called == 1)/nrow(ball_model_data)
    
      set.seed(574)
      ball_rf_model <- randomForest(ball_called ~., 
                         data = ball_model_data, 
                         ntree = 100,
                         nodesize = 1,
                         mtry = 47,
                         classwt = c(wn, wy)) 
      
      test_row <- bounded_results_matrix %>%
       filter(player == player_list[i],
               as.character(batter_side) == batter_list[i],
               as.character(tagged_pitch_type) == pitch_list[i]) %>%
        select(-c("preds", "player", "batter_side", "tagged_pitch_type", "model_number", "pitch_split"))

      ball_model_data <- ball_model_data %>%
        mutate(across(1:25, as.character)) %>%
        mutate(across(1:25, as.integer))

      test_row$ball_called <- as.factor(0)

      row_list <- vector()

      for(x in 1:25){
        if(sum(ball_model_data[, x]) == 0){
          row_list <- append(row_list, x)
          }
      }
      
      test_row$index <- seq(1, 25)
      
      test_row <- test_row[-row_list, ]

      test_row <- test_row %>%
        mutate(across(1:25, as.factor))
      
      test_row_no_index <- test_row %>%
        select(-index)
      
      ball_model_preds <- predict(ball_rf_model, test_row_no_index, type = "prob")
      
      bounded_preds <- cbind(test_row, ball_model_preds[ ,2])
      
      colnames(bounded_preds) <- c(colnames(test_row), "model_preds")
      
      bounded_individual_pitchers_ball[[i]] <- bounded_results_matrix %>%
       filter(player == player_list[i],
               as.character(batter_side) == batter_list[i],
               as.character(tagged_pitch_type) == pitch_list[i])
      
      for(z in 1:25){
        if(z %in% row_list){
           bounded_individual_pitchers_ball[[i]][z, 53] <- NA
        } else{
           bounded_individual_pitchers_ball[[i]][z, 53] <- as.list(bounded_preds[which(bounded_preds$index == z), 50])
        }
      }
      }
}

final_bounded_results_matrix_ball <- bounded_individual_pitchers_ball %>%
  bind_rows() %>%
  filter(!is.na(preds))

colnames(final_bounded_results_matrix_ball) <- str_replace(colnames(final_bounded_results_matrix_ball), "postpitch_", "")

final_bounded_results_matrix_ball <- final_bounded_results_matrix_ball %>%
  pivot_longer(1:25, names_to = "column", values_to = "in_zone") %>%
  filter(in_zone != 0) %>%
  select(-in_zone) %>%
  rename("zone" = column) %>%
  mutate(zone = as.integer(zone)) %>%
  select(zone, player, batter_side, tagged_pitch_type, pitch_split, preds)
```

# Command Zone Rating: The Calculation

## Component 1: Magnitude - Average Zone Difference

The magnitude component of CZR comes in the form of average zone differential by pitcher across all pitches thrown, regardless of zone. This stand-alone value is calculated and appended to a table in the code below:
```{r}
final_zone_difference_table <- metrics_reduced_model_data %>%
  filter(team == "Notre Dame") %>%
  group_by(player) %>%
  mutate(total_zone_diff = sum(zone_diff, na.rm = TRUE)) %>%
  mutate(total_pitches = n()) %>%
  select(player, total_zone_diff, total_pitches) %>%
  distinct() %>%
  mutate(zone_diff_per_pitch = total_zone_diff / total_pitches) %>%
  arrange(zone_diff_per_pitch)
```

## Component 2: Impact - Command Score 

The average impact of a pitch thrown by pitchers is found by calculating the expected value of balls called and strikes hit for contact across all missed pitches, divided by the total number of pitches thrown across eligible pitcher, batter side, and pitch type combinations (those through which a model was built).

Command Score requires the total number of missed pitches in each zone by batter side and pitch type for all eligible pitchers, as stored below:
```{r}
final_misses_thrown_by_zone_side_type <- metrics_reduced_model_data %>%
  filter(team == "Notre Dame") %>%
  filter(zone_diff > 0) %>%
  group_by(player, batter_side, tagged_pitch_type, postpitch) %>%
  summarise(total_misses_by_zone_side_type = n()) %>%
  drop_na() %>%
  rename("zone" = postpitch)
```

The Score also requires the total number of pitches thrown in a zone by batter side and tagged pitch type, regardless of it being classified by a miss in the model:
```{r}
final_pitches_thrown_by_zone_side_type <- metrics_reduced_model_data %>%
  filter(team == "Notre Dame") %>%
  group_by(player, batter_side, tagged_pitch_type, postpitch) %>%
  summarise(total_pitches_by_zone_side_type = n()) %>%
  drop_na() %>%
  rename("zone" = postpitch)
```

We are able to gather all of our necessary components for CZR into one dataframe through nested joins, as performed here on the final matrices of bounded predictions from the models built on pitcher, batter side, and pitch type combinations above:
```{r}
final_bounded_results_matrix_strike <- final_bounded_results_matrix_strike %>%
  left_join(final_zone_difference_table, 
            by = "player") %>%
  left_join(final_misses_thrown_by_zone_side_type,
            by = c("player", "batter_side", "tagged_pitch_type", "zone")) %>%
  left_join(final_pitches_thrown_by_zone_side_type,
            by = c("player", "batter_side", "tagged_pitch_type", "zone")) %>%
  select(-c("total_pitches", "pitch_split"))

final_bounded_results_matrix_ball <- final_bounded_results_matrix_ball %>%
  left_join(final_zone_difference_table, 
            by = "player") %>%
  left_join(final_misses_thrown_by_zone_side_type,
            by = c("player", "batter_side", "tagged_pitch_type", "zone")) %>%
  left_join(final_pitches_thrown_by_zone_side_type,
            by = c("player", "batter_side", "tagged_pitch_type", "zone")) %>%
  select(-c("total_pitches", "pitch_split"))

head(final_bounded_results_matrix_strike, 20)
head(final_bounded_results_matrix_ball, 50)

final_bounded_results <- rbind(final_bounded_results_matrix_ball, final_bounded_results_matrix_strike)
final_bounded_results <- final_bounded_results %>%
  arrange(player)

head(final_bounded_results)
```


The above data frame provides all individual pieces of CZR. To calculate Command Score, multiply the predictions by their corresponding quantities of missed pitches within the zone, and sum the products together in the form of a linear combination (Total Probability)
```{r}
final_metric_command_scores <- final_bounded_results %>%
  mutate(command_score_total = (preds * total_misses_by_zone_side_type)) %>%
  group_by(player) %>%
  summarise(total_probability = sum(command_score_total))
```

Find the total number of pitches thrown across eligible pitch type, player, batter side combinations, storing the sums in a table for the CZR calculation:
```{r}
final_metric_command_scores_scales <- final_bounded_results%>%
  group_by(player) %>%
  summarise(total_pitches = sum(total_pitches_by_zone_side_type))
```

The following code calculates the Command Score for each pitcher by dividing the total expected balls called and strikes for contact on misses by the total number of pitches thrown. 

We also calculate the Command Zone Rating (CZR) by multiplying the Command Score of a given pitcher (the Impact) by their corresponding Average Zone Differential per pitch (the Magnitude): 
```{r}
final_czr_table <- final_bounded_results %>%
  left_join(final_metric_command_scores,
            by = "player") %>%
  left_join(final_metric_command_scores_scales,
            by = "player") %>%
  select(-c(total_misses_by_zone_side_type, total_pitches_by_zone_side_type, zone, batter_side, tagged_pitch_type, total_zone_diff, preds)) %>%
  distinct() %>%
  mutate(command_score = total_probability / total_pitches,
         command_zone_rating = command_score * zone_diff_per_pitch) %>%
  select(player, command_score, zone_diff_per_pitch, command_zone_rating) %>%
  arrange(command_zone_rating)

final_czr_table

final_czr_table_mean <- final_czr_table %>%
  summarize(mean_czr = mean(command_zone_rating))

final_czr_table$mean_czr <- rep(final_czr_table_mean$mean_czr[1], nrow(final_czr_table))
```

While the raw scores of CZR may prove satisfactory, normalizing the results on a 100 scale may make the CZR scores more interpretable. Hence, we find the CZR+ scores here:
```{r}
final_czr_table <- final_czr_table %>%
  mutate(command_zone_rating_normalized = round(command_zone_rating * 100 / mean_czr, 0)) %>%
  select(-mean_czr)

final_czr_table
```

As such, scores below 100 correspond to above-average command. Scores above 100 correspond to below-average command.

We can arrange this final table by each component of the CZR (Impact and Magnitude):
```{r}
final_czr_table %>%
  arrange(command_score)

final_czr_table %>%
  arrange(zone_diff_per_pitch)
```

# Command Zone Rating: Visualizations for Analysis
## Preliminary Visualizations

As with any new metric, we are interested in determining if any relationship exists between the results of CZR and established pitching performance metrics (in this case, ERA and WHIP).

We will begin by plotting ERA and WHIP over time to gain an understanding of the metrics' development alongside team failures and successes:
```{r}
# Aggregate ERA by game date
agg_era <-
  aggregate(pregamepitching$pre_era_pitch, list("Game Date" = pregamepitching$date), mean, na.rm = TRUE)

agg_era

# Create time series plot
gg1 <- ggplot(data = agg_era, aes(x = agg_era$`Game Date`, y = agg_era$x, group = 1)) +
  geom_line(linetype = "dashed", color = "navy") +
  geom_point(color = "gold") +
  xlab("Game Date") +
  ylab("Team ERA") +
  ggtitle("Team Average ERA Over the Season") +
  theme(axis.line = element_line(colour = "black"), # Set axis line as black
        panel.grid.major = element_blank(), # Remove grid
        panel.grid.minor = element_blank(), # Remove grid
        panel.border = element_blank(), # Remove grid
        panel.background = element_blank())

gg1
```

Noteworthy performances may be added accordingly below:
```{r}
# Aggregate ERA by game date
agg_era <-
  aggregate(pregamepitching$pre_era_pitch, list("Game Date" = pregamepitching$date), mean, na.rm = TRUE)

agg_era <- agg_era %>%
  clean_names() %>%
  mutate(game_date = mdy(game_date))

# Create time series plot
gg2 <- ggplot(data = agg_era, aes(x = agg_era$game_date, y = agg_era$x, group = 1)) +
  geom_line(linetype = "dashed", color = "navy") +
  geom_point(color = "gold") +
  xlab("Game Date") +
  ylab("Team ERA") +
  ggtitle("Team Average ERA Over the Season") +
  theme(axis.line = element_line(colour = "black"), # Set axis line as black
        panel.grid.major = element_blank(), # Remove grid
        panel.grid.minor = element_blank(), # Remove grid
        panel.border = element_blank(), # Remove grid
        panel.background = element_blank()) +
  geom_vline(xintercept = mdy("4/19/2022"), color = "red") +
  geom_text(aes(x = mdy("4/12/2022"), y = 11.0 , label = "Duke Weekend Ends: 25 Runs Allowed"), color = "red")  

gg2
```

For greater granularity, we will investigate the average ERA by pitcher over time:
```{r}
# Aggregate ERA by game date and pitcher
agg_plyr_era <- aggregate(pregamepitching$pre_era_pitch ~ pregamepitching$date + pregamepitching$player, data = pregamepitching, FUN = mean, na.rm = TRUE)

agg_plyr_era <- agg_plyr_era %>%
  clean_names() %>%
  rename(game_date = "pregamepitching_date",
         player = "pregamepitching_player",
         pre_era_pitch = "pregamepitching_pre_era_pitch") %>%
  mutate(game_date = mdy(game_date))

# Create data sets for starting pitchers

tyrell_era <- agg_plyr_era %>% 
  filter(player == "Aidan Tyrell")
tyrell_era

temple_era <- agg_plyr_era %>% 
  filter(player == "Austin Temple")
temple_era

jm_era <- agg_plyr_era %>% 
  filter(player == "John Michael Bertrand")
jm_era

findlay_era <- agg_plyr_era %>% 
  filter(player == "Jack Findlay")
findlay_era

# Plot average ERA for starters over the season
gg2 <- ggplot() +
  geom_line(data = tyrell_era, aes(x = game_date, y = pre_era_pitch, group = 1, colour = "Tyrell"), size = 1.5) +
  geom_line(data = temple_era, aes(x = game_date, y = pre_era_pitch, group = 1, colour = "Temple"), size = 1.5) +
  geom_line(data = jm_era, aes(x = game_date, y = pre_era_pitch, group = 1, colour = "Bertrand"), size = 1.5) +
  geom_line(data = findlay_era, aes(x = game_date, y = pre_era_pitch, group = 1, colour = "Findlay"), size = 1.5) +
  ylim(0, 6) +
  xlab("Game Date") +
  ylab("ERA") +
  ggtitle("Average ERA for Starting Pitchers") +
  scale_color_manual(name = "Players", values = c("Tyrell" = "gray", "Temple" = "navy", "Bertrand"="gold", "Findlay" = "green")) +
   theme(axis.line = element_line(colour = "black"), # Set axis line as black
        panel.grid.major = element_blank(), # Remove grid
        panel.grid.minor = element_blank(), # Remove grid
        panel.border = element_blank(), # Remove grid
        panel.background = element_blank())

gg2
```

The same procedure for WHIP is conducted here (investigating team WHIP and individual starter WHIP over time):
```{r}
# Convert infinite values to NA
metrics_reduced_model_data$whip[!is.finite(metrics_reduced_model_data$whip)] <- NA

# Remove NA values for WHIP
whip_data <- metrics_reduced_model_data %>% 
  filter(as.character(metrics_reduced_model_data$whip) != "NA" 
)

# Aggregate WHIP by game date
agg_whip <-
  aggregate(whip_data$whip, list("Game Date" = whip_data$date), mean)

agg_whip <- agg_whip %>%
  clean_names() 


# Create time series plot
gg3 <- ggplot(data = agg_whip, aes(x = agg_whip$game_date, y = agg_whip$x, group = 1)) +
  geom_line(linetype = "dashed", color = "navy") +
  geom_point(color = "gold") +
  ylim(0, NA) +
  xlab("Game Date") +
  ylab("Team WHIP") +
  ggtitle("Team Average WHIP Over the Season") +
  geom_vline(xintercept = mdy("4/19/2022"), color = "red") +
  geom_text(aes(x = mdy("4/12/2022"), y = 6.0 , label = "Duke Weekend Ends: 25 Runs Allowed"), color = "red") +
  theme(axis.line = element_line(colour = "black"), # Set axis line as black
        panel.grid.major = element_blank(), # Remove grid
        panel.grid.minor = element_blank(), # Remove grid
        panel.border = element_blank(), # Remove grid
        panel.background = element_blank())
  
gg3
```

The following plot attains more granularity by viewing the average WHIP over time by starting pitcher:
```{r}
# Aggregate WHIP by game date and pitcher
agg_plyr_whip <- aggregate(whip_data$whip ~ whip_data$date + whip_data$player, data = whip_data, FUN = mean, na.rm = TRUE)

agg_plyr_whip

# Create data sets for each starter
tyrell_whip <- agg_plyr_whip %>% 
  filter(agg_plyr_whip$`whip_data$player` == "Aidan Tyrell")
tyrell_whip

temple_whip <- agg_plyr_whip %>% 
  filter(agg_plyr_whip$`whip_data$player` == "Austin Temple")
temple_whip

jm_whip <- agg_plyr_whip %>% 
  filter(agg_plyr_whip$`whip_data$player` == "John Michael Bertrand")
jm_whip

findlay_whip <- agg_plyr_whip %>% 
  filter(agg_plyr_whip$`whip_data$player` == "Jack Findlay")
findlay_whip

# Create scatter plot for starters' WHIP

gg4 <- ggplot() +
  geom_point(data = tyrell_whip, aes(x = `whip_data$date`, y = `whip_data$whip`, group = 1, colour = "Tyrell")) +
  geom_point(data = temple_whip, aes(x = `whip_data$date`, y = `whip_data$whip`, group = 1, colour = "Temple")) +
  geom_point(data = jm_whip, aes(x = `whip_data$date`, y = `whip_data$whip`, group = 1, colour = "Bertrand")) +
  geom_point(data = findlay_whip, aes(x = `whip_data$date`, y = `whip_data$whip`, group = 1, colour = "Findlay")) +
  ylim(0, 8) +
  xlab("Game Date") +
  ylab("WHIP") +
  ggtitle("Average WHIP for Starting Pitchers") +
  scale_color_manual(name = "Players", values = c("Tyrell" = "gray", "Temple" = "navy", "Bertrand"="gold", "Findlay" = "green")) +
  theme(axis.line = element_line(colour = "black"), # Set axis line as black
        panel.grid.major = element_blank(), # Remove grid
        panel.grid.minor = element_blank(), # Remove grid
        panel.border = element_blank(), # Remove grid
        panel.background = element_blank())

gg4

# Aggregate WHIP by players 

plyr_whip <- aggregate(whip_data$whip ~  whip_data$player, data = whip_data, FUN = mean, na.rm = TRUE)

plyr_whip

# Filter by starters
starters_whip <- plyr_whip %>% 
  filter(plyr_whip$`whip_data$player` == "Aidan Tyrell" | plyr_whip$`whip_data$player` == "Austin Temple" | plyr_whip$`whip_data$player` == "John Michael Bertrand" | plyr_whip$`whip_data$player` == "Jack Findlay")

# Create bar chart for starters' average WHIP
gg5 <- ggplot(data = starters_whip, aes(x = starters_whip$`whip_data$player`, y = starters_whip$`whip_data$whip`, fill = starters_whip$`whip_data$player`)) +
  geom_col() +
  theme(legend.position="none") +
  xlab("Player") +
  ylab("Average WHIP") +
  ggtitle("Average WHIP for Starting Pitchers") +
  theme(axis.line = element_line(colour = "black"), # Set axis line as black
        panel.grid.major = element_blank(), # Remove grid
        panel.grid.minor = element_blank(), # Remove grid
        panel.border = element_blank(), # Remove grid
        panel.background = element_blank()) +
   scale_fill_manual(values = c("gray", "navy", "gold", "green"))

gg5
```

## Command Zone Rating (CZR) Visualizations

With a baseline for ERA and WHIP established, we can investigate the relationships between CZR and rigid pitching performance metrics (if any)

We begin with the relationship between ERA and CZR. Ideally, a positive relationship appears in the data (low CZR values associated with high pitching command success and, as a result, lower ERA scores over time):
```{r}
library(reshape2)
czr_plot_data <- last_pitching_appearance_pregame %>%
  filter(player %in% player_list) %>%
  select(player, pre_era_pitch, pre_b_avg_pitch, whip) %>%
  distinct() %>%
  left_join(final_czr_table,
            by = "player") %>%
  select(-c(command_score, zone_diff_per_pitch, command_zone_rating)) 

gg7 <- ggplot(data = czr_plot_data, aes(x = command_zone_rating_normalized, y = pre_era_pitch)) +
  geom_point(color = "navy", size = 1.5) +
  geom_smooth(se = FALSE, color = "gold", size = 1.5) +
  xlab("Command Zone Rating (CZR)") +
  ylab("ERA") +
  ggtitle("CZR vs. Earned Run Average (ERA)") +
   theme(axis.line = element_line(colour = "black"), # Set axis line as black
        panel.grid.major = element_blank(), # Remove grid
        panel.grid.minor = element_blank(), # Remove grid
        panel.border = element_blank(), # Remove grid
        panel.background = element_blank())

gg7
```

Next, we will investigate the relationship between WHIP and CZR. Ideally, a positive relationship appears in the data (low CZR values associated with high pitching command success and, as a result, lower WHIP scores over time):
```{r}
gg8 <- ggplot(data = czr_plot_data, aes(x = command_zone_rating_normalized, y = whip)) +
  geom_point(color = "navy", size = 1.5) +
  geom_smooth(se = FALSE, color = "gold", size = 1.5) +
  xlab("Command Zone Rating (CZR)") +
  ylab("WHIP") +
  ggtitle("CZR vs. WHIP") +
   theme(axis.line = element_line(colour = "black"), # Set axis line as black
        panel.grid.major = element_blank(), # Remove grid
        panel.grid.minor = element_blank(), # Remove grid
        panel.border = element_blank(), # Remove grid
        panel.background = element_blank()) +
  geom_text(x = 86, y = 3.2, label = "Jackson Dennies", vjust = 1) +
  geom_text(x = 96, y = 1.875, label = "Alex Rao", vjust = 1)

gg8
```

For additional reference, the relationship between opponent batting average and CZR is shown below:
```{r}
gg9 <- ggplot(data = czr_plot_data, aes(x = command_zone_rating_normalized, y = pre_b_avg_pitch)) +
  geom_point(color = "navy", size = 1.5) +
  geom_smooth(se = FALSE, color = "gold", size = 1.5) +
  xlab("Command Zone Rating (CZR)") +
  ylab("Opponent Batting Average") +
  ggtitle("CZR vs. Opponent Batting Average") +
   theme(axis.line = element_line(colour = "black"), # Set axis line as black
        panel.grid.major = element_blank(), # Remove grid
        panel.grid.minor = element_blank(), # Remove grid
        panel.border = element_blank(), # Remove grid
        panel.background = element_blank()) +
  geom_text(x = 116, y = 0.364, label = "Sammy Cooper", vjust = 1)

gg9
```

## CZR Scores Analysis Workspace

As mentioned, the final CZR table, as well as its associated predictions table, allows for various calculations and analysis by zone. The following space serves as for additional visualizations, aggregations, and grouping based on the structure of the prediction results:
```{r}
final_bounded_results %>%
  filter(player == "John Michael Bertrand",
         batter_side == "Right",
         tagged_pitch_type == "Fastball")
```

```{r}
bounded_results_matrix %>%
  select(player, pre_era_pitch, whip) %>%
  arrange(whip) %>%
  distinct()
```

Command Zone Rating (CZR)
